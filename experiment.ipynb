import os
import random
import json
import numpy as np

# Если вы будете использовать torch / tf позже — сразу заложим задел
try:
    import torch
except ImportError:
    torch = None

try:
    import tensorflow as tf
except ImportError:
    tf = None

# --- Подключение Google Drive (работает только в Colab) ---
try:
    from google.colab import drive  # type: ignore
    IN_COLAB = True
except ImportError:
    IN_COLAB = False

if IN_COLAB:
    drive.mount("/content/drive")
    BASE_DIR = "/content/drive/MyDrive/digital_marketing_conversion"
else:
    # Локальный fallback — можно поменять под себя
    BASE_DIR = os.path.abspath("./digital_marketing_conversion")

DATA_DIR = os.path.join(BASE_DIR, "data")
MODELS_DIR = os.path.join(BASE_DIR, "models")
PLOTS_DIR = os.path.join(BASE_DIR, "plots")
REPORTS_DIR = os.path.join(BASE_DIR, "reports")
ARTIFACTS_DIR = os.path.join(BASE_DIR, "artifacts")

for d in [BASE_DIR, DATA_DIR, MODELS_DIR, PLOTS_DIR, REPORTS_DIR, ARTIFACTS_DIR]:
    os.makedirs(d, exist_ok=True)

print("BASE_DIR:", BASE_DIR)
print("DATA_DIR:", DATA_DIR)
print("MODELS_DIR:", MODELS_DIR)
print("PLOTS_DIR:", PLOTS_DIR)
print("REPORTS_DIR:", REPORTS_DIR)
print("ARTIFACTS_DIR:", ARTIFACTS_DIR)

# --- Функция для установки случайных зерен ---
def set_global_seed(seed: int = 42) -> None:
    random.seed(seed)
    np.random.seed(seed)

    if torch is not None:
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        # Дополнительно чуть жёстче фиксируем детерминизм
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

    if tf is not None:
        try:
            tf.random.set_seed(seed)
        except Exception:
            pass

    print(f"[INFO] Глобальное зерно случайности установлено: {seed}")

set_global_seed(42)

# --- Проверка наличия GPU ---
if torch is not None and torch.cuda.is_available():
    print("[INFO] PyTorch видит GPU:", torch.cuda.get_device_name(0))
elif tf is not None and len(tf.config.list_physical_devices("GPU")) > 0:
    print("[INFO] TensorFlow видит GPU:", tf.config.list_physical_devices("GPU"))
else:
    print("[WARN] GPU не обнаружен (или библиотеки DL ещё не установлены).")
    print("       Но для датасета на 8000 строк это не критично.")

# Базовые библиотеки анализа данных и визуализации
!pip install -q pandas numpy matplotlib seaborn

# ML-стек (дальше пригодится, но уже сейчас можно поставить)
!pip install -q scikit-learn imbalanced-learn xgboost lightgbm shap umap-learn

# Работа с Kaggle API и конфигами
!pip install -q kaggle pyyaml

import os
import zipfile
from pathlib import Path

if IN_COLAB:
    from google.colab import files  # type: ignore

    print(
        "Пожалуйста, загрузите kaggle.json (из профиля Kaggle → Account → Create New Token)."
    )
    uploaded = files.upload()  # Откроется диалог выбора файла

    if "kaggle.json" not in uploaded:
        raise FileNotFoundError(
            "Файл kaggle.json не найден среди загруженных. "
            "Убедитесь, что выбрали правильный файл."
        )

    # Настройка Kaggle API
    kaggle_dir = os.path.join(os.path.expanduser("~"), ".kaggle")
    os.makedirs(kaggle_dir, exist_ok=True)

    with open("kaggle.json", "r") as f_in:
        token = json.load(f_in)

    kaggle_json_path = os.path.join(kaggle_dir, "kaggle.json")
    with open(kaggle_json_path, "w") as f_out:
        json.dump(token, f_out)

    os.chmod(kaggle_json_path, 0o600)
    print("[INFO] kaggle.json настроен.")

    # Скачивание датасета
    print("[INFO] Скачиваю датасет 'Predict Conversion in Digital Marketing'...")
    !kaggle datasets download -d rabieelkharoua/predict-conversion-in-digital-marketing-dataset -p {DATA_DIR} --unzip

    # Проверим, какие CSV появились
    csv_files = list(Path(DATA_DIR).glob("*.csv"))
    print("[INFO] Найдены CSV-файлы в DATA_DIR:")
    for p in csv_files:
        print("   -", p.name)

else:
    print(
        "[WARN] Не в Colab: этот блок рассчитан на Google Colab и может не работать локально."
    )
