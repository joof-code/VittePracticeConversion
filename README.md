# Система повышения конверсии клиентов

Учебный проект преддипломной практики, посвящённый построению и внедрению прототипа системы интеллектуального анализа данных для
прогнозирования конверсии клиентов и поддержки маркетинговых решений.

Проект включает два основных компонента:

1. **Исследовательский блок в Jupyter Notebook**  
   – анализ датасета по цифровому маркетингу;  
   – предобработка и генерация производных признаков;  
   – обучение и сравнение моделей (Logistic Regression, RandomForest, XGBoost, MLP);  
   – выбор чемпионской модели (RandomForest), сегментация по децилям и KMeans;  
   – сохранение артефактов обучения для последующего использования в веб-приложении.

2. **Веб-приложение «Система повышения конверсии» (Flask)**  
   – оценка отдельного клиента по форме;  
   – пакетная оценка по CSV-файлам;  
   – дашборд по конверсии клиентов и приоритетным сегментам;  
   – история запусков и карточки клиентов;  
   – использование заранее обученных моделей и кластеризатора.

---

## 1. Структура репозитория

```text
.
├─ data/                      # Исходные данные (CSV из Kaggle / CRM)
│   └─ marketing_campaign.csv
├─ instance/
│   └─ digital_marketing.db
├─ configs/
│   └─ flask_serving_config.json
├─ models/                 # Сохранённые модели и вспомогательные файлы
│   ├─ rf_best_pipeline.joblib
│   ├─ xgb_best_pipeline.joblib
│   ├─ mlp_conversion_model.keras
│   ├─ kmeans_model.joblib
│   ├─ cluster_scaler.joblib
│   ├─ flask_serving_config.json
│   └─ client_segmentation_deciles.csv
├─ app/
│   ├─ app.py                 # Flask-приложение
│   ├─ ml_service.py          # Загрузка моделей, функции скоринга
│   ├─ models.py              # Описание таблиц SQLAlchemy (BatchRun, Lead)
│   ├─ templates/             # HTML-шаблоны (dashboard, формы, история запусков и т.д.)
│   └─ static/                # CSS, JS, изображения
├─ requirements.txt
└─ README.md
````

---

## 2. Требования

* Python **3.10+**
* pip (устанавливается вместе с Python)
* Git (для клонирования, можно заменить на скачивание архива)

Все необходимые библиотеки (Flask, SQLAlchemy, scikit-learn, xgboost, keras/TF, numpy, pandas и др.) перечислены в `requirements.txt`.

---

## 3. Установка проекта

### 3.1. Клонирование репозитория

```bash
git clone https://github.com/joof-code/VittePracticeConversion conversion-project
cd conversion-project
```

*(если проект скачан архивом — просто распакуйте его и перейдите в каталог проекта)*

### 3.2. Создание и активация виртуального окружения

**Windows (PowerShell / cmd):**

```bash
python -m venv .venv
.venv\Scripts\activate
```

**Linux / macOS (bash/zsh):**

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3.3. Установка зависимостей

```bash
pip install -r requirements.txt
```

---

## 4. Работа с ноутбуками (исследования и обучение моделей)

### 4.1. Подготовка данных

В проекте данные загружаются **автоматически через Kaggle API**.

1. Скачайте файл `kaggle.json` из своего профиля Kaggle  
   (Account → API → Create New Token).

2. Поместите `kaggle.json`:
   - локально: в каталог `~/.kaggle/` (Linux/macOS) или  
     `C:\Users\<USER>\.kaggle\` (Windows);
   - в Google Colab / другой среде: в корень проекта и выполните в ячейке
     загрузку в `~/.kaggle/` (в ноутбуке уже есть пример кода).

3. Убедитесь, что установлен пакет `kaggle`.
   При запуске ноутбука он при необходимости будет установлен автоматически.

4. При выполнении первых ячеек ноутбука вызывается Kaggle API, датасет
   скачивается и распаковывается в каталог `data/` в нужном формате.

### 4.2. Запуск Jupyter Notebook

На активированном виртуальном окружении:

```bash
jupyter notebook
```

Либо:

```bash
jupyter lab
```

В открывшемся браузере откройте `Vitte_predict_conversion.ipynb` и последовательно выполните все ячейки (`Run all`), чтобы:
   * провести EDA и визуализировать распределения признаков, целевую переменную, корреляции;
   * выполнить очистку, генерацию производных признаков и разбиение выборок.
   * обучение базовых и ансамблевых моделей;
   * оценку качества по ROC AUC, PR-AUC, F1-мере, лифт- и гейн-кривым;
   * выбор и калибровку чемпионской модели (RandomForest);
   * обучение KMeans и формирование сегментов;
   * экспорт артефактов в каталог `artifacts/` (модели, scaler, конфиг `flask_serving_config.json`, файл с децилями и т.д.).

После успешного выполнения ноутбука в каталоге `artifacts/` должны находиться все нужные файлы, которые будет использовать веб-приложение.

---

## 5. Запуск веб-приложения (Flask)

### 5.1. Подготовка окружения

Убедитесь, что:

* виртуальное окружение **активировано**;
* зависимости установлены (`pip install -r requirements.txt`);
* артефакты моделей лежат в каталоге `artifacts/` (если вы не переобучали модель, можно использовать уже подготовленные файлы из репозитория).

### 5.2. Инициализация базы данных

При первом запуске приложение автоматически создаст SQLite-базу (`digital_marketing.db`) и таблицы `BatchRun` и `Lead` с помощью `SQLAlchemy.create_all()`.

Дополнительных действий обычно не требуется.

### 5.3. Запуск приложения

Из корня проекта:

**Вариант 1. Через `python`:**

```bash
cd app
python app.py
```

**Вариант 2. Через `flask run` (если в коде настроен `FLASK_APP`):**

```bash
set FLASK_APP=app.py      # Windows
export FLASK_APP=app.py   # Linux/macOS
flask run
```

По умолчанию приложение будет доступно по адресу:

```text
http://127.0.0.1:5000/
```

### 5.4. Основные разделы интерфейса

* **«Дашборд»**
  Стартовый экран с общей статистикой по базе: количество клиентов, число пакетных запусков, распределение по приоритетным сегментам, информация о последнем запуске.

* **«Оценить клиента»**
  Форма ввода данных по одному клиенту (общие данные, параметры кампании, поведение на сайте, email-активность и лояльность).
  После нажатия кнопки расчёта система:

  * обращается к `MLService` в `ml_service.py`;
  * подготавливает признаки (в том числе производные);
  * применяет модель RandomForest и кластеризатор KMeans;
  * отображает вероятность конверсии, приоритетный сегмент, дециль и кластер.
    Результат одновременно записывается в таблицу `Lead`.

* **«Пакетная оценка (CSV)»**
  Форма загрузки CSV-файла с набором клиентов:

  * на шаге 1 пользователь выбирает файл и задаёт имя запуска;
  * на шаге 2 отображается сводка по последнему запуску и первые строки результата;
  * в таблицу клиентов добавляются поля `rf_score`, `predicted_conversion`, `rf_decile`, `priority_segment`, `cluster_kmeans`.
    Для каждого запуска создаётся запись в таблице `BatchRun`, результаты можно выгрузить в CSV.

* **«История запусков»**
  Список всех пакетных расчётов с указанием даты, числа клиентов, среднего скорингового балла, доли предсказанных конверсий и порога классификации.
  Для выбранного запуска можно открыть детальный список клиентов и посмотреть отдельную карточку клиента.

---

## 6. Контрольный пример

Чтобы проверить работу системы «от начала и до конца»:

1. **Одиночная оценка**

   * Запустите приложение и откройте вкладку **«Оценить клиента»**.
   * Заполните форму тестовыми данными (возраст, доход, канал и тип кампании, показатели сайта, email-активность, предыдущие покупки и баллы лояльности).
   * Нажмите кнопку расчёта.
     На экране появятся:

     * оценочная вероятность конверсии;
     * приоритетный сегмент (High / Medium / Low);
     * дециль по вероятности;
     * номер поведенческого кластера KMeans.
       Запись будет добавлена в базу, а число клиентов в дашборде увеличится на 1.

2. **Пакетная оценка**

   * Подготовьте небольшой CSV-файл (например, `test_leads.csv`) со строками клиентов и набором столбцов, перечисленных на странице «Пакетная оценка (CSV)».
   * Перейдите на эту вкладку, выберите файл, задайте имя запуска и нажмите кнопку «Запустить расчёт».
   * После завершения обработки:

     * просмотрите сводку по запуску на той же странице;
     * откройте запуск в разделе «История запусков»;
     * убедитесь, что для клиентов рассчитаны скоринговые баллы, сегменты и кластеры;
     * при необходимости скачайте результирующий CSV.

3. **Проверка дашборда**

   * Вернитесь на вкладку «Дашборд» и убедитесь, что:

     * количество клиентов в базе увеличилось;
     * появилась запись о последнем пакетном запуске;
     * статистика по сегментам обновилась.

---

## 7. Возможные направления развития

* интеграция с реальной CRM-системой и веб-аналитикой вместо учебного датасета;
* добавление мониторинга качества моделей и автоматической переобучаемости;
* расширение набора визуализаций в дашборде (лифт-кривые, распределение конверсии по каналам, вклад кластера в выручку);
* внедрение авторизации пользователей и разграничения прав доступа;
* контейнеризация (Docker) и развёртывание на сервере организации.

Проект предназначен для учебных целей и может служить основой для дальнейшей доработки и внедрения в корпоративную среду.
